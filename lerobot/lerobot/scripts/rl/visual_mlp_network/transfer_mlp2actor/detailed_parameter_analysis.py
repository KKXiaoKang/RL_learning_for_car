#!/usr/bin/env python3
"""
è¯¦ç»†åˆ†æMLP BCå’ŒSAC Actorå‚æ•°å·®å¼‚
æ‰¾å‡ºå…·ä½“å“ªäº›å‚æ•°å±‚å¯¼è‡´äº†å‚æ•°æ•°ç›®ä¸ä¸€è‡´
"""

import os
import torch
from safetensors import safe_open
from collections import defaultdict
from typing import Dict, List, Tuple, Any

# Import the MLPBCConfig to make it available for torch.load
try:
    from lerobot.common.policies.sac.mlp_bc_model.configuration_mlp_bc import MLPBCConfig
    torch.serialization.add_safe_globals([MLPBCConfig])
except ImportError:
    print("Warning: Could not import MLPBCConfig")

class DetailedParameterAnalyzer:
    """è¯¦ç»†å‚æ•°åˆ†æå™¨"""
    
    def __init__(self):
        self.mlp_bc_params = {}
        self.sac_actor_params = {}
    
    def load_mlp_bc_checkpoint(self, checkpoint_path: str) -> Dict[str, torch.Tensor]:
        """åŠ è½½MLP BC checkpoint"""
        print(f"Loading MLP BC checkpoint from: {checkpoint_path}")
        
        try:
            try:
                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=True)
            except Exception:
                checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
            
            if 'model_state_dict' in checkpoint:
                model_params = checkpoint['model_state_dict']
            elif 'model' in checkpoint:
                model_params = checkpoint['model']
            elif 'state_dict' in checkpoint:
                model_params = checkpoint['state_dict']
            else:
                model_params = checkpoint
            
            # åªä¿ç•™tensorå‚æ•°
            tensor_params = {}
            for key, value in model_params.items():
                if isinstance(value, torch.Tensor):
                    tensor_params[key] = value
            
            self.mlp_bc_params = tensor_params
            return tensor_params
            
        except Exception as e:
            raise RuntimeError(f"Error loading MLP BC checkpoint: {e}")
    
    def load_sac_actor_parameters(self, checkpoint_dir: str) -> Dict[str, torch.Tensor]:
        """åŠ è½½SAC actorå‚æ•°"""
        print(f"Loading SAC actor parameters from: {checkpoint_dir}")
        
        model_path = os.path.join(checkpoint_dir, "pretrained_model", "model.safetensors")
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")
        
        try:
            actor_params = {}
            with safe_open(model_path, framework="pt", device="cpu") as f:
                keys = f.keys()
                actor_keys = [key for key in keys if 'actor' in key.lower()]
                
                for key in actor_keys:
                    actor_params[key] = f.get_tensor(key)
            
            self.sac_actor_params = actor_params
            return actor_params
            
        except Exception as e:
            raise RuntimeError(f"Error loading SAC parameters: {e}")
    
    def analyze_parameter_structure(self):
        """åˆ†æå‚æ•°ç»“æ„"""
        print("\n" + "="*80)
        print("DETAILED PARAMETER STRUCTURE ANALYSIS")
        print("="*80)
        
        # åˆ†æMLP BCå‚æ•°
        print(f"\nğŸ“Š MLP BC Parameters (Total: {len(self.mlp_bc_params)})")
        print("-" * 60)
        mlp_bc_total_params = 0
        mlp_bc_groups = self._group_parameters(self.mlp_bc_params, "MLP_BC")
        
        for group, params in mlp_bc_groups.items():
            group_params = sum(p.numel() for p in params.values())
            mlp_bc_total_params += group_params
            print(f"\n{group}:")
            for name, param in sorted(params.items()):
                print(f"  {name:50} {str(param.shape):15} {param.numel():>8} params")
            print(f"  {'='*50} {'Subtotal:':15} {group_params:>8} params")
        
        print(f"\nğŸ¯ MLP BC Total Parameters: {mlp_bc_total_params:,}")
        
        # åˆ†æSAC Actorå‚æ•°
        print(f"\nğŸ“Š SAC Actor Parameters (Total: {len(self.sac_actor_params)})")
        print("-" * 60)
        sac_actor_total_params = 0
        sac_actor_groups = self._group_parameters(self.sac_actor_params, "SAC_Actor")
        
        for group, params in sac_actor_groups.items():
            group_params = sum(p.numel() for p in params.values())
            sac_actor_total_params += group_params
            print(f"\n{group}:")
            for name, param in sorted(params.items()):
                print(f"  {name:50} {str(param.shape):15} {param.numel():>8} params")
            print(f"  {'='*50} {'Subtotal:':15} {group_params:>8} params")
        
        print(f"\nğŸ¯ SAC Actor Total Parameters: {sac_actor_total_params:,}")
        
        # è®¡ç®—å·®å¼‚
        param_diff = abs(mlp_bc_total_params - sac_actor_total_params)
        print(f"\nâ— Parameter Difference: {param_diff:,} parameters")
        
        return mlp_bc_groups, sac_actor_groups, param_diff
    
    def _group_parameters(self, params: Dict[str, torch.Tensor], model_name: str) -> Dict[str, Dict[str, torch.Tensor]]:
        """æŒ‰åŠŸèƒ½æ¨¡å—åˆ†ç»„å‚æ•°"""
        groups = defaultdict(dict)
        
        for name, param in params.items():
            if 'normalization' in name or 'normalize' in name:
                # å½’ä¸€åŒ–ç›¸å…³å‚æ•°
                groups['Normalization'][name] = param
            elif 'encoder' in name and 'state_encoder' in name:
                # çŠ¶æ€ç¼–ç å™¨
                groups['State Encoder'][name] = param
            elif 'encoder' in name and 'image' in name:
                # å›¾åƒç¼–ç å™¨
                groups['Image Encoder'][name] = param
            elif 'network' in name:
                # ä¸»å¹²ç½‘ç»œ
                groups['Main Network'][name] = param
            elif 'mean_layer' in name:
                # å‡å€¼å±‚
                groups['Mean Layer'][name] = param
            elif 'std_layer' in name:
                # æ ‡å‡†å·®å±‚
                groups['Std Layer'][name] = param
            else:
                # å…¶ä»–å‚æ•°
                groups['Other'][name] = param
        
        return dict(groups)
    
    def find_missing_parameters(self):
        """æ‰¾å‡ºç¼ºå¤±çš„å‚æ•°"""
        print("\n" + "="*80)
        print("MISSING PARAMETER ANALYSIS")
        print("="*80)
        
        # æå–å‚æ•°åï¼ˆå»æ‰å‰ç¼€ï¼‰
        mlp_bc_simple_names = set()
        sac_actor_simple_names = set()
        
        for name in self.mlp_bc_params.keys():
            # æå–æ ¸å¿ƒå‚æ•°å
            simple_name = self._extract_core_param_name(name)
            mlp_bc_simple_names.add(simple_name)
        
        for name in self.sac_actor_params.keys():
            simple_name = self._extract_core_param_name(name)
            sac_actor_simple_names.add(simple_name)
        
        # æ‰¾å‡ºå·®å¼‚
        only_in_mlp_bc = mlp_bc_simple_names - sac_actor_simple_names
        only_in_sac_actor = sac_actor_simple_names - mlp_bc_simple_names
        
        print(f"\nğŸ” Parameters only in MLP BC ({len(only_in_mlp_bc)}):")
        for name in sorted(only_in_mlp_bc):
            # æ‰¾åˆ°åŸå§‹å‚æ•°åå’Œå½¢çŠ¶
            original_names = [k for k in self.mlp_bc_params.keys() if self._extract_core_param_name(k) == name]
            for orig_name in original_names:
                param = self.mlp_bc_params[orig_name]
                print(f"  {orig_name:50} {str(param.shape):15} {param.numel():>8} params")
        
        print(f"\nğŸ” Parameters only in SAC Actor ({len(only_in_sac_actor)}):")
        for name in sorted(only_in_sac_actor):
            original_names = [k for k in self.sac_actor_params.keys() if self._extract_core_param_name(k) == name]
            for orig_name in original_names:
                param = self.sac_actor_params[orig_name]
                print(f"  {orig_name:50} {str(param.shape):15} {param.numel():>8} params")
        
        return only_in_mlp_bc, only_in_sac_actor
    
    def _extract_core_param_name(self, full_name: str) -> str:
        """æå–æ ¸å¿ƒå‚æ•°å"""
        # å»æ‰æ¨¡å‹å‰ç¼€ï¼Œä¿ç•™æ ¸å¿ƒç»“æ„
        name = full_name
        
        # å»æ‰å¸¸è§å‰ç¼€
        prefixes_to_remove = ['actor.', 'critic.', 'policy.', 'model.']
        for prefix in prefixes_to_remove:
            if name.startswith(prefix):
                name = name[len(prefix):]
                break
        
        return name
    
    def analyze_shape_compatibility(self):
        """åˆ†æå½¢çŠ¶å…¼å®¹æ€§"""
        print("\n" + "="*80)
        print("SHAPE COMPATIBILITY ANALYSIS")
        print("="*80)
        
        # æ‰¾åˆ°å¯¹åº”çš„å‚æ•°å¯¹
        matched_pairs = []
        mlp_bc_unmatched = []
        sac_actor_unmatched = []
        
        # ç®€åŒ–çš„åŒ¹é…ç­–ç•¥
        for mlp_name, mlp_param in self.mlp_bc_params.items():
            mlp_core = self._extract_core_param_name(mlp_name)
            
            # å¯»æ‰¾SACä¸­çš„å¯¹åº”å‚æ•°
            sac_match = None
            for sac_name, sac_param in self.sac_actor_params.items():
                sac_core = self._extract_core_param_name(sac_name)
                if mlp_core == sac_core:
                    sac_match = (sac_name, sac_param)
                    break
            
            if sac_match:
                matched_pairs.append((mlp_name, mlp_param, sac_match[0], sac_match[1]))
            else:
                mlp_bc_unmatched.append((mlp_name, mlp_param))
        
        # æ‰¾åˆ°SACä¸­æœªåŒ¹é…çš„å‚æ•°
        matched_sac_names = {pair[2] for pair in matched_pairs}
        for sac_name, sac_param in self.sac_actor_params.items():
            if sac_name not in matched_sac_names:
                sac_actor_unmatched.append((sac_name, sac_param))
        
        # æ‰“å°åŒ¹é…ç»“æœ
        print(f"\nâœ… Matched Parameter Pairs ({len(matched_pairs)}):")
        print(f"{'MLP BC':50} {'Shape':15} {'SAC Actor':50} {'Shape':15} {'Compatible':10}")
        print("-" * 140)
        
        compatible_count = 0
        for mlp_name, mlp_param, sac_name, sac_param in matched_pairs:
            compatible = mlp_param.shape == sac_param.shape
            if compatible:
                compatible_count += 1
            
            compat_str = "âœ… Yes" if compatible else "âŒ No"
            print(f"{mlp_name:50} {str(mlp_param.shape):15} {sac_name:50} {str(sac_param.shape):15} {compat_str}")
        
        print(f"\nğŸ“Š Compatibility Summary: {compatible_count}/{len(matched_pairs)} pairs are shape-compatible")
        
        # æ‰“å°æœªåŒ¹é…çš„å‚æ•°
        if mlp_bc_unmatched:
            print(f"\nâŒ Unmatched MLP BC Parameters ({len(mlp_bc_unmatched)}):")
            for name, param in mlp_bc_unmatched:
                print(f"  {name:50} {str(param.shape):15} {param.numel():>8} params")
        
        if sac_actor_unmatched:
            print(f"\nâŒ Unmatched SAC Actor Parameters ({len(sac_actor_unmatched)}):")
            for name, param in sac_actor_unmatched:
                print(f"  {name:50} {str(param.shape):15} {param.numel():>8} params")
        
        return matched_pairs, mlp_bc_unmatched, sac_actor_unmatched
    
    def generate_replacement_strategy(self):
        """ç”Ÿæˆæ›¿æ¢ç­–ç•¥"""
        print("\n" + "="*80)
        print("REPLACEMENT STRATEGY")
        print("="*80)
        
        matched_pairs, mlp_bc_unmatched, sac_actor_unmatched = self.analyze_shape_compatibility()
        
        print("\nğŸ”„ Replacement Plan:")
        print("1. Direct Parameter Transfer (Shape Compatible):")
        
        transferable_pairs = []
        for mlp_name, mlp_param, sac_name, sac_param in matched_pairs:
            if mlp_param.shape == sac_param.shape:
                transferable_pairs.append((mlp_name, sac_name))
                print(f"   {mlp_name} â†’ {sac_name}")
        
        print(f"\n2. Parameters Requiring Special Handling:")
        if mlp_bc_unmatched:
            print("   MLP BC Unique Parameters (may need to be ignored):")
            for name, param in mlp_bc_unmatched:
                print(f"     - {name} ({param.shape})")
        
        if sac_actor_unmatched:
            print("   SAC Actor Unique Parameters (may need default initialization):")
            for name, param in sac_actor_unmatched:
                print(f"     - {name} ({param.shape})")
        
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥æ›¿æ¢
        total_mlp_bc_transferable = sum(
            self.mlp_bc_params[mlp_name].numel() 
            for mlp_name, _ in transferable_pairs
        )
        
        total_sac_actor_params = sum(p.numel() for p in self.sac_actor_params.values())
        
        print(f"\nğŸ“Š Transfer Coverage:")
        print(f"   Transferable parameters: {total_mlp_bc_transferable:,}")
        print(f"   Total SAC Actor parameters: {total_sac_actor_params:,}")
        print(f"   Coverage: {total_mlp_bc_transferable/total_sac_actor_params*100:.1f}%")
        
        return transferable_pairs, mlp_bc_unmatched, sac_actor_unmatched


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Detailed Parameter Structure Analyzer")
    print("="*80)
    
    # æ–‡ä»¶è·¯å¾„
    mlp_bc_checkpoint = "/home/lab/RL/lerobot/outputs/mlp_bc_grasp_training_aligned_2/checkpoint_step_2000.pt"
    sac_checkpoint_dir = "/home/lab/RL/lerobot/outputs/train/2025-08-18/17-36-30_15_grasp_box_kuavo_reward_mse_demo01_action_06_yes_dataset_temp01_discount095_fps10_seed1000s/checkpoints/last"
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DetailedParameterAnalyzer()
    
    try:
        # åŠ è½½å‚æ•°
        analyzer.load_mlp_bc_checkpoint(mlp_bc_checkpoint)
        analyzer.load_sac_actor_parameters(sac_checkpoint_dir)
        
        # æ‰§è¡Œåˆ†æ
        analyzer.analyze_parameter_structure()
        analyzer.find_missing_parameters()
        analyzer.generate_replacement_strategy()
        
        print("\nâœ… Analysis completed successfully!")
        
    except Exception as e:
        print(f"âŒ Error during analysis: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
