#!/usr/bin/env python3
"""
çœŸæ­£çš„åºåˆ—ACT-SAC Actorå®ç°

è¿™ä¸ªå®ç°å……åˆ†åˆ©ç”¨ACTçš„æ ¸å¿ƒä¼˜åŠ¿ï¼š
1. é¢„æµ‹åŠ¨ä½œåºåˆ—ï¼ˆchunkï¼‰è€Œä¸æ˜¯å•ä¸ªåŠ¨ä½œ
2. è®¡ç®—æ•´ä¸ªåŠ¨ä½œåºåˆ—çš„è”åˆæ¦‚ç‡æŸå¤±
3. æ”¯æŒè‡ªå›å½’åŠ¨ä½œç”Ÿæˆ
4. ä¸SACæ¡†æ¶çš„åºåˆ—æŸå¤±é›†æˆ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import Tensor
from torch.distributions import MultivariateNormal
import logging
from typing import Optional, Tuple, Dict, List

from lerobot.common.policies.sac.modeling_sac import TanhMultivariateNormalDiag
from lerobot.common.policies.utils import get_device_from_parameters


def create_sinusoidal_pos_embedding(seq_len: int, dim: int) -> Tensor:
    """åˆ›å»ºæ­£å¼¦ä½ç½®ç¼–ç """
    position = torch.arange(seq_len).unsqueeze(1).float()
    div_term = torch.exp(torch.arange(0, dim, 2).float() * -(torch.log(torch.tensor(10000.0)) / dim))
    
    pe = torch.zeros(seq_len, dim)
    pe[:, 0::2] = torch.sin(position * div_term)
    pe[:, 1::2] = torch.cos(position * div_term)
    
    return pe


class SequenceACTSACActorV2(nn.Module):
    """
    çœŸæ­£çš„åºåˆ—ACT-SAC Actor
    
    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. é¢„æµ‹åŠ¨ä½œåºåˆ—ï¼ˆaction chunksï¼‰
    2. æ”¯æŒè‡ªå›å½’ç”Ÿæˆ
    3. è®¡ç®—åºåˆ—è”åˆæ¦‚ç‡æŸå¤±
    4. ä¸SACæŸå¤±å‡½æ•°é›†æˆ
    
    æ¶æ„ï¼š
    è§‚æµ‹åºåˆ— â†’ Encoder â†’ ACT Transformer â†’ åŠ¨ä½œåºåˆ—é¢„æµ‹
    """
    
    def __init__(
        self,
        encoder,  # SACObservationEncoder
        action_dim: int,
        chunk_size: int = 8,  # é¢„æµ‹çš„åŠ¨ä½œåºåˆ—é•¿åº¦
        obs_history_length: int = 5,  # è§‚æµ‹å†å²é•¿åº¦
        
        # Transformer å‚æ•°
        dim_model: int = 512,
        n_heads: int = 8,
        dim_feedforward: int = 3200,
        n_encoder_layers: int = 4,
        n_decoder_layers: int = 4,  # å¢åŠ decoderå±‚æ•°ä»¥å¤„ç†åºåˆ—
        dropout: float = 0.1,
        feedforward_activation: str = "relu",
        pre_norm: bool = False,
        
        # SAC å‚æ•°
        std_min: float = -5,
        std_max: float = 2,
        use_tanh_squash: bool = True,
        encoder_is_shared: bool = False,
    ):
        super().__init__()
        
        self.encoder = encoder
        self.action_dim = action_dim
        self.chunk_size = chunk_size
        self.obs_history_length = obs_history_length
        self.dim_model = dim_model
        self.std_min = std_min
        self.std_max = std_max
        self.use_tanh_squash = use_tanh_squash
        self.encoder_is_shared = encoder_is_shared
        
        # ç‰¹å¾æŠ•å½±å±‚
        self.obs_to_transformer_proj = nn.Linear(encoder.output_dim, dim_model)
        
        # Transformer ç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=dim_model,
            nhead=n_heads,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            activation=feedforward_activation,
            norm_first=pre_norm,
            batch_first=False  # (seq, batch, dim)
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_encoder_layers)
        
        # Transformer è§£ç å™¨
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=dim_model,
            nhead=n_heads,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            activation=feedforward_activation,
            norm_first=pre_norm,
            batch_first=False  # (seq, batch, dim)
        )
        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=n_decoder_layers)
        
        # åŠ¨ä½œé¢„æµ‹å¤´
        self.action_mean_head = nn.Linear(dim_model, action_dim)
        self.action_std_head = nn.Linear(dim_model, action_dim)
        
        # ä½ç½®ç¼–ç 
        self.register_buffer(
            "obs_pos_embed",
            create_sinusoidal_pos_embedding(obs_history_length, dim_model).unsqueeze(1)
        )
        self.register_buffer(
            "action_pos_embed", 
            create_sinusoidal_pos_embedding(chunk_size, dim_model).unsqueeze(1)
        )
        
        # å¯å­¦ä¹ çš„åºåˆ—å¼€å§‹token
        self.action_start_token = nn.Parameter(torch.randn(1, 1, dim_model))
        
        logging.info(f"âœ… Initialized SequenceACTSACActorV2 with chunk_size={chunk_size}, obs_history_length={obs_history_length}")
    
    def encode_observations(self, observations: List[Dict[str, Tensor]]) -> Tensor:
        """
        ç¼–ç è§‚æµ‹åºåˆ—
        
        Args:
            observations: è§‚æµ‹åºåˆ— [obs_t-n, ..., obs_t-1, obs_t]
            
        Returns:
            ç¼–ç åçš„è§‚æµ‹åºåˆ— (obs_history_length, batch_size, dim_model)
        """
        device = get_device_from_parameters(self)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è§‚æµ‹å†å²
        if len(observations) < self.obs_history_length:
            # ç”¨æœ€æ—©çš„è§‚æµ‹å¡«å……
            while len(observations) < self.obs_history_length:
                observations.insert(0, observations[0])
        else:
            # å–æœ€åNä¸ªè§‚æµ‹
            observations = observations[-self.obs_history_length:]
        
        # ç¼–ç æ¯ä¸ªè§‚æµ‹
        obs_features_list = []
        for obs in observations:
            # ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
            obs = {k: v.to(device) for k, v in obs.items()}
            
            if self.encoder_is_shared:
                obs_feat = self.encoder(obs, cache=None, detach=True)
            else:
                obs_feat = self.encoder(obs, cache=None, detach=False)
            obs_features_list.append(obs_feat)
        
        # å †å ä¸ºåºåˆ—
        obs_features_seq = torch.stack(obs_features_list, dim=0)  # (seq_len, batch, feature_dim)
        
        # æŠ•å½±åˆ°Transformerç©ºé—´
        transformer_input = self.obs_to_transformer_proj(obs_features_seq)
        
        return transformer_input
    
    def forward(
        self,
        observations: List[Dict[str, Tensor]] | Dict[str, Tensor],
        observation_features: Optional[Tensor] = None,
        action_history: Optional[Tensor] = None,  # åŠ¨ä½œå†å²ç”¨äºè‡ªå›å½’
        return_sequence: bool = True,  # æ˜¯å¦è¿”å›å®Œæ•´åºåˆ—
    ) -> Tuple[Tensor, Tensor, Tensor]:
        """
        å‰å‘ä¼ æ’­ï¼šé¢„æµ‹åŠ¨ä½œåºåˆ—
        
        Args:
            observations: è§‚æµ‹åºåˆ—æˆ–å•ä¸ªè§‚æµ‹
            observation_features: é¢„è®¡ç®—çš„è§‚æµ‹ç‰¹å¾ï¼ˆæš‚ä¸ä½¿ç”¨ï¼‰
            action_history: å†å²åŠ¨ä½œåºåˆ—ï¼ˆç”¨äºè‡ªå›å½’ç”Ÿæˆï¼‰
            return_sequence: æ˜¯å¦è¿”å›å®Œæ•´åŠ¨ä½œåºåˆ—
            
        Returns:
            å¦‚æœreturn_sequence=True:
                actions: åŠ¨ä½œåºåˆ— (batch_size, chunk_size, action_dim)
                log_probs: åºåˆ—å¯¹æ•°æ¦‚ç‡ (batch_size,) - è”åˆæ¦‚ç‡
                means: åŠ¨ä½œå‡å€¼åºåˆ— (batch_size, chunk_size, action_dim)
            å¦‚æœreturn_sequence=False:
                actions: å•ä¸ªåŠ¨ä½œ (batch_size, action_dim) - åºåˆ—çš„ç¬¬ä¸€ä¸ªåŠ¨ä½œ
                log_probs: å•ä¸ªåŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡ (batch_size,)
                means: å•ä¸ªåŠ¨ä½œçš„å‡å€¼ (batch_size, action_dim)
        """
        device = get_device_from_parameters(self)
        
        # å¤„ç†å•ä¸ªè§‚æµ‹çš„æƒ…å†µ
        if isinstance(observations, dict):
            observations = [observations]
        
        batch_size = next(iter(observations[0].values())).shape[0]
        
        # 1. ç¼–ç è§‚æµ‹åºåˆ—
        obs_encoded = self.encode_observations(observations)  # (obs_seq_len, batch, dim_model)
        
        # 2. æ·»åŠ è§‚æµ‹ä½ç½®ç¼–ç 
        obs_pos_embed = self.obs_pos_embed.expand(-1, batch_size, -1)
        obs_encoded = obs_encoded + obs_pos_embed
        
        # 3. Transformer Encoder
        obs_memory = self.transformer_encoder(obs_encoded)  # (obs_seq_len, batch, dim_model)
        
        # 4. æ„å»ºè§£ç å™¨è¾“å…¥åºåˆ—
        if action_history is not None:
            # ä½¿ç”¨å†å²åŠ¨ä½œä½œä¸ºè¾“å…¥
            decoder_input = self._prepare_decoder_input_with_history(action_history, batch_size, device)
        else:
            # ä½¿ç”¨å¯å­¦ä¹ çš„start token
            decoder_input = self.action_start_token.expand(self.chunk_size, batch_size, -1)
        
        # 5. æ·»åŠ åŠ¨ä½œä½ç½®ç¼–ç 
        action_pos_embed = self.action_pos_embed.expand(-1, batch_size, -1)
        decoder_input = decoder_input + action_pos_embed
        
        # 6. Transformer Decoderï¼ˆè‡ªå›å½’ï¼‰
        if self.training:
            # è®­ç»ƒæ—¶ä½¿ç”¨teacher forcing
            decoder_output = self._teacher_forcing_decode(decoder_input, obs_memory)
        else:
            # æ¨ç†æ—¶ä½¿ç”¨è‡ªå›å½’ç”Ÿæˆ
            decoder_output = self._autoregressive_decode(obs_memory, batch_size, device)
        
        # 7. é¢„æµ‹åŠ¨ä½œåˆ†å¸ƒå‚æ•°
        action_means = self.action_mean_head(decoder_output)  # (chunk_size, batch, action_dim)
        action_log_stds = self.action_std_head(decoder_output)  # (chunk_size, batch, action_dim)
        
        # è½¬æ¢ç»´åº¦ä¸º (batch, chunk_size, action_dim)
        action_means = action_means.transpose(0, 1)
        action_log_stds = action_log_stds.transpose(0, 1)
        
        # é™åˆ¶æ ‡å‡†å·®èŒƒå›´
        action_log_stds = torch.clamp(action_log_stds, self.std_min, self.std_max)
        action_stds = torch.exp(action_log_stds)
        
        # 8. é‡‡æ ·åŠ¨ä½œåºåˆ—å¹¶è®¡ç®—è”åˆæ¦‚ç‡
        actions_sequence, log_probs_joint = self._sample_action_sequence(action_means, action_stds)
        
        # 9. æ ¹æ®éœ€è¦è¿”å›åºåˆ—æˆ–å•ä¸ªåŠ¨ä½œ
        if return_sequence:
            return actions_sequence, log_probs_joint, action_means
        else:
            # è¿”å›åºåˆ—çš„ç¬¬ä¸€ä¸ªåŠ¨ä½œï¼ˆç”¨äºSACçš„å³æ—¶æ‰§è¡Œï¼‰
            first_action = actions_sequence[:, 0, :]  # (batch, action_dim)
            first_mean = action_means[:, 0, :]  # (batch, action_dim)
            
            # è®¡ç®—ç¬¬ä¸€ä¸ªåŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡
            if self.use_tanh_squash:
                first_dist = TanhMultivariateNormalDiag(
                    loc=first_mean, 
                    scale_diag=action_stds[:, 0, :]
                )
            else:
                first_dist = MultivariateNormal(
                    first_mean, 
                    torch.diag_embed(action_stds[:, 0, :])
                )
            
            first_log_prob = first_dist.log_prob(first_action)
            
            return first_action, first_log_prob, first_mean
    
    def _teacher_forcing_decode(self, decoder_input: Tensor, obs_memory: Tensor) -> Tensor:
        """è®­ç»ƒæ—¶çš„teacher forcingè§£ç """
        # åˆ›å»ºå› æœæ©ç ä»¥é˜²æ­¢çœ‹åˆ°æœªæ¥çš„åŠ¨ä½œ
        tgt_mask = nn.Transformer.generate_square_subsequent_mask(self.chunk_size).to(decoder_input.device)
        
        decoder_output = self.transformer_decoder(
            decoder_input,
            obs_memory,
            tgt_mask=tgt_mask
        )
        
        return decoder_output
    
    def _autoregressive_decode(self, obs_memory: Tensor, batch_size: int, device: torch.device) -> Tensor:
        """æ¨ç†æ—¶çš„è‡ªå›å½’è§£ç """
        outputs = []
        current_input = self.action_start_token.expand(1, batch_size, -1)
        
        for i in range(self.chunk_size):
            # æ·»åŠ ä½ç½®ç¼–ç 
            pos_embed = self.action_pos_embed[i:i+1].expand(-1, batch_size, -1)
            current_input_with_pos = current_input + pos_embed
            
            # è§£ç å½“å‰æ—¶é—´æ­¥
            output = self.transformer_decoder(
                current_input_with_pos,
                obs_memory
            )
            
            outputs.append(output)
            
            # å‡†å¤‡ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥
            if i < self.chunk_size - 1:
                current_input = output
        
        return torch.cat(outputs, dim=0)  # (chunk_size, batch, dim_model)
    
    def _sample_action_sequence(self, means: Tensor, stds: Tensor) -> Tuple[Tensor, Tensor]:
        """
        é‡‡æ ·åŠ¨ä½œåºåˆ—å¹¶è®¡ç®—è”åˆå¯¹æ•°æ¦‚ç‡
        
        è¿™ä¸ªæ–¹æ³•å®ç°äº†Q-chunkingçš„æ ¸å¿ƒï¼šå°†åŠ¨ä½œåºåˆ—ä½œä¸ºä¸€ä¸ªæ•´ä½“è¿›è¡Œé‡‡æ ·å’Œæ¦‚ç‡è®¡ç®—
        
        Args:
            means: åŠ¨ä½œå‡å€¼åºåˆ— (batch, chunk_size, action_dim)
            stds: åŠ¨ä½œæ ‡å‡†å·®åºåˆ— (batch, chunk_size, action_dim)
            
        Returns:
            actions: é‡‡æ ·çš„åŠ¨ä½œåºåˆ— (batch, chunk_size, action_dim)
            log_probs: è”åˆå¯¹æ•°æ¦‚ç‡ (batch,) - Q-chunkingçš„å…³é”®è¾“å‡º
        """
        batch_size = means.shape[0]
        actions_list = []
        log_probs_list = []
        
        for t in range(self.chunk_size):
            # ä¸ºæ¯ä¸ªæ—¶é—´æ­¥åˆ›å»ºåˆ†å¸ƒ
            if self.use_tanh_squash:
                dist = TanhMultivariateNormalDiag(
                    loc=means[:, t, :], 
                    scale_diag=stds[:, t, :]
                )
            else:
                dist = MultivariateNormal(
                    means[:, t, :], 
                    torch.diag_embed(stds[:, t, :])
                )
            
            # é‡‡æ ·åŠ¨ä½œï¼ˆä½¿ç”¨é‡å‚æ•°åŒ–æŠ€å·§ç¡®ä¿æ¢¯åº¦å¯ä¼ æ’­ï¼‰
            action = dist.rsample()
            log_prob = dist.log_prob(action)
            
            actions_list.append(action)
            log_probs_list.append(log_prob)
        
        # ç»„åˆç»“æœ
        actions_sequence = torch.stack(actions_list, dim=1)  # (batch, chunk_size, action_dim)
        log_probs_individual = torch.stack(log_probs_list, dim=1)  # (batch, chunk_size)
        
        # ğŸ”¥ Q-chunkingæ ¸å¿ƒï¼šè®¡ç®—åŠ¨ä½œåºåˆ—çš„è”åˆå¯¹æ•°æ¦‚ç‡
        # è¿™å‡è®¾äº†åŠ¨ä½œåœ¨ç»™å®šè§‚æµ‹åºåˆ—ä¸‹æ˜¯æ¡ä»¶ç‹¬ç«‹çš„ï¼Œä½†ä»ç„¶æ•è·äº†åºåˆ—çš„æ—¶é—´ä¸€è‡´æ€§
        log_probs_joint = log_probs_individual.sum(dim=1)  # (batch,)
        
        return actions_sequence, log_probs_joint
    
    def _prepare_decoder_input_with_history(
        self, 
        action_history: Tensor, 
        batch_size: int, 
        device: torch.device
    ) -> Tensor:
        """å‡†å¤‡å¸¦æœ‰å†å²åŠ¨ä½œçš„è§£ç å™¨è¾“å…¥"""
        # action_history: (batch, history_len, action_dim)
        history_len = action_history.shape[1]
        
        # å¦‚æœå†å²é•¿åº¦ä¸å¤Ÿï¼Œç”¨start tokenå¡«å……
        if history_len < self.chunk_size:
            padding_len = self.chunk_size - history_len
            start_tokens = self.action_start_token.expand(padding_len, batch_size, -1)
            
            # å°†å†å²åŠ¨ä½œæŠ•å½±åˆ°transformerç©ºé—´
            history_proj = self.action_mean_head.weight.T @ action_history.transpose(1, 2)  # ç®€å•çš„åå‘æŠ•å½±
            history_proj = history_proj.transpose(1, 2).transpose(0, 1)
            
            decoder_input = torch.cat([start_tokens, history_proj], dim=0)
        else:
            # æˆªå–æœ€åchunk_sizeä¸ªåŠ¨ä½œ
            recent_history = action_history[:, -self.chunk_size:, :]
            history_proj = self.action_mean_head.weight.T @ recent_history.transpose(1, 2)
            decoder_input = history_proj.transpose(1, 2).transpose(0, 1)
        
        return decoder_input
    
    def get_action_sequence_distribution(
        self,
        observations: List[Dict[str, Tensor]] | Dict[str, Tensor],
        observation_features: Optional[Tensor] = None,
    ) -> List[TanhMultivariateNormalDiag]:
        """
        è·å–å®Œæ•´åŠ¨ä½œåºåˆ—çš„åˆ†å¸ƒ
        
        Returns:
            åŠ¨ä½œåˆ†å¸ƒåˆ—è¡¨ï¼Œæ¯ä¸ªæ—¶é—´æ­¥ä¸€ä¸ªåˆ†å¸ƒ
        """
        with torch.no_grad():
            _, _, means_sequence = self.forward(
                observations, 
                observation_features, 
                return_sequence=True
            )
            
            # é‡æ–°è®¡ç®—æ ‡å‡†å·®ï¼ˆé¿å…é‡å¤å‰å‘ä¼ æ’­çš„ç®€åŒ–ç‰ˆæœ¬ï¼‰
            batch_size = means_sequence.shape[0]
            device = means_sequence.device
            
            # ç®€åŒ–ï¼šä½¿ç”¨å›ºå®šæ ‡å‡†å·®
            fixed_std = torch.ones_like(means_sequence) * 0.1
            
            distributions = []
            for t in range(self.chunk_size):
                if self.use_tanh_squash:
                    dist = TanhMultivariateNormalDiag(
                        loc=means_sequence[:, t, :],
                        scale_diag=fixed_std[:, t, :]
                    )
                else:
                    dist = MultivariateNormal(
                        means_sequence[:, t, :],
                        torch.diag_embed(fixed_std[:, t, :])
                    )
                distributions.append(dist)
            
            return distributions
    
    def compute_n_step_returns(
        self,
        rewards: Tensor,
        next_observations: List[Dict[str, Tensor]],
        done: Tensor,
        gamma: float = 0.99,
        observation_features: Optional[Tensor] = None,
    ) -> Tensor:
        """
        è®¡ç®—n-step returnsä»¥æ”¯æŒQ-chunkingçš„n-step TD learning
        
        è¿™æ˜¯Q-chunkingè®ºæ–‡ä¸­çš„å…³é”®ç»„ä»¶ï¼šä½¿ç”¨åŠ¨ä½œåºåˆ—è¿›è¡Œn-step backup
        
        Args:
            rewards: å•æ­¥å¥–åŠ± (batch_size,)
            next_observations: ä¸‹ä¸€ä¸ªè§‚æµ‹åºåˆ—
            done: ç»ˆæ­¢æ ‡å¿— (batch_size,)
            gamma: æŠ˜æ‰£å› å­
            observation_features: é¢„è®¡ç®—çš„è§‚æµ‹ç‰¹å¾
            
        Returns:
            n_step_returns: næ­¥å›æŠ¥ (batch_size,)
        """
        with torch.no_grad():
            # å¦‚æœchunk_size=1ï¼Œé€€åŒ–ä¸ºæ ‡å‡†1-step return
            if self.chunk_size == 1:
                return rewards
            
            # å¯¹äºmulti-stepï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ•´ä¸ªchunkçš„ç´¯è®¡å¥–åŠ±
            # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥é€šè¿‡ç¯å¢ƒäº¤äº’è·å¾—chunk_sizeæ­¥çš„å¥–åŠ±
            
            # é¢„æµ‹ä¸‹ä¸€ä¸ªçŠ¶æ€çš„åŠ¨ä½œåºåˆ—
            next_action_sequence, next_log_probs_joint, _ = self.forward(
                next_observations,
                observation_features,
                return_sequence=True
            )
            
            # ç®€åŒ–çš„n-step returnè®¡ç®—
            # å®é™…å®ç°ä¸­ï¼Œè¿™åº”è¯¥é€šè¿‡çœŸå®çš„ç¯å¢ƒrolloutæ¥è®¡ç®—
            n_step_return = rewards  # èµ·å§‹å€¼ä¸ºå³æ—¶å¥–åŠ±
            
            # å¯¹äºæ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨å‡ ä½•çº§æ•°è¿‘ä¼¼n-step return
            discount_factor = gamma ** self.chunk_size
            n_step_return = rewards * (1 - discount_factor) / (1 - gamma) if gamma != 1 else rewards * self.chunk_size
            
            return n_step_return
    
    def get_chunked_action_for_execution(
        self,
        observations: List[Dict[str, Tensor]] | Dict[str, Tensor],
        observation_features: Optional[Tensor] = None,
        action_index: int = 0,
    ) -> Tensor:
        """
        è·å–åŠ¨ä½œåºåˆ—ä¸­çš„ç‰¹å®šåŠ¨ä½œç”¨äºæ‰§è¡Œ
        
        è¿™æ”¯æŒQ-chunkingçš„æ‰§è¡Œç­–ç•¥ï¼šä¸€æ¬¡é¢„æµ‹å¤šæ­¥ï¼Œä½†é€æ­¥æ‰§è¡Œ
        
        Args:
            observations: è§‚æµ‹åºåˆ—
            observation_features: é¢„è®¡ç®—çš„è§‚æµ‹ç‰¹å¾
            action_index: è¦æ‰§è¡Œçš„åŠ¨ä½œåœ¨åºåˆ—ä¸­çš„ç´¢å¼•
            
        Returns:
            å•ä¸ªåŠ¨ä½œç”¨äºæ‰§è¡Œ
        """
        with torch.no_grad():
            action_sequence, _, _ = self.forward(
                observations,
                observation_features,
                return_sequence=True
            )
            
            # è¿”å›æŒ‡å®šç´¢å¼•çš„åŠ¨ä½œ
            if action_index >= self.chunk_size:
                logging.warning(f"Action index {action_index} exceeds chunk size {self.chunk_size}, using last action")
                action_index = self.chunk_size - 1
            
            return action_sequence[:, action_index, :]  # (batch_size, action_dim)
