#!/usr/bin/env python3
"""
ACT-SAC æ··åˆæ¶æ„æµ‹è¯•è„šæœ¬

éªŒè¯ACT-SACå®ç°çš„æ­£ç¡®æ€§å’Œå…¼å®¹æ€§
"""

import torch
import torch.nn as nn
from torch import Tensor
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)

# æµ‹è¯•å¯¼å…¥
try:
    from lerobot.common.policies.sac.configuration_sac import SACConfig
    from lerobot.common.policies.sac.modeling_sac import SACPolicy
    from lerobot.common.policies.sac.modeling_sac_act_actor import ACTSACActor
    from lerobot.common.policies.sac.modeling_sac_sequence_act_actor import SequenceACTSACActorV2
    from lerobot.configs.types import PolicyFeature, FeatureType
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    exit(1)


def create_test_config(use_act_actor: bool = True, use_sequence: bool = False):
    """åˆ›å»ºæµ‹è¯•é…ç½®"""
    
    # åŸºç¡€ç‰¹å¾é…ç½®
    input_features = {
        "observation.state": PolicyFeature(type=FeatureType.STATE, shape=(10,)),  # 10ç»´çŠ¶æ€è§‚æµ‹
    }
    
    output_features = {
        "action": PolicyFeature(type=FeatureType.ACTION, shape=(4,)),  # 4ç»´åŠ¨ä½œ
    }
    
    config = SACConfig(
        input_features=input_features,
        output_features=output_features,
        
        # ACTé…ç½®
        use_act_actor=use_act_actor,
        use_sequence_act_actor=use_sequence,
        obs_history_length=3,
        
        # è½»é‡åŒ–é…ç½®ä»¥ä¾¿æµ‹è¯•
        act_dim_model=128,
        act_n_heads=4,
        act_dim_feedforward=512,
        act_n_encoder_layers=2,
        act_n_decoder_layers=1,
        act_dropout=0.1,
        
        # SACé…ç½®
        num_critics=2,
        shared_encoder=True,
        latent_dim=64,
        
        # BCé…ç½®
        bc_initial_weight=0.5,
        bc_final_weight=0.1,
        bc_decay_steps=1000,
        
        # å½’ä¸€åŒ–é…ç½®
        dataset_stats={
            "observation.state": {
                "min": [0.0] * 10,
                "max": [1.0] * 10,
            },
            "action": {
                "min": [-1.0] * 4,
                "max": [1.0] * 4,
            },
        },
    )
    
    return config


def create_test_data(batch_size: int = 4, state_dim: int = 10, action_dim: int = 4):
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    
    observations = {
        "observation.state": torch.randn(batch_size, state_dim)
    }
    
    actions = torch.randn(batch_size, action_dim)
    expert_actions = torch.randn(batch_size, action_dim)
    
    return observations, actions, expert_actions


def test_traditional_sac():
    """æµ‹è¯•ä¼ ç»ŸSAC Actor"""
    print("\nğŸ”§ æµ‹è¯•ä¼ ç»ŸSAC Actor...")
    
    config = create_test_config(use_act_actor=False)
    policy = SACPolicy(config=config)
    
    observations, actions, expert_actions = create_test_data()
    
    # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
    selected_actions = policy.select_action(observations)
    print(f"  - åŠ¨ä½œé€‰æ‹©: {selected_actions.shape}")
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    batch = {
        "state": observations,
        "action": actions,
        "expert_action": expert_actions,
        "training_step": 100,
    }
    
    loss_dict = policy.forward(batch, model="actor")
    print(f"  - ActoræŸå¤±: {loss_dict['loss_actor'].item():.4f}")
    
    print("âœ… ä¼ ç»ŸSAC Actoræµ‹è¯•é€šè¿‡")


def test_act_sac():
    """æµ‹è¯•ACT-SAC Actor"""
    print("\nğŸ¤– æµ‹è¯•ACT-SAC Actor...")
    
    config = create_test_config(use_act_actor=True, use_sequence=False)
    policy = SACPolicy(config=config)
    
    observations, actions, expert_actions = create_test_data()
    
    # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
    selected_actions = policy.select_action(observations)
    print(f"  - åŠ¨ä½œé€‰æ‹©: {selected_actions.shape}")
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    batch = {
        "state": observations,
        "action": actions,
        "expert_action": expert_actions,
        "training_step": 100,
    }
    
    loss_dict = policy.forward(batch, model="actor")
    print(f"  - ActoræŸå¤±: {loss_dict['loss_actor'].item():.4f}")
    
    print("âœ… ACT-SAC Actoræµ‹è¯•é€šè¿‡")


def test_sequence_act_sac():
    """æµ‹è¯•åºåˆ—ACT-SAC Actor"""
    print("\nğŸ“š æµ‹è¯•åºåˆ—ACT-SAC Actor...")
    
    config = create_test_config(use_act_actor=True, use_sequence=True)
    policy = SACPolicy(config=config)
    
    observations, actions, expert_actions = create_test_data()
    
    # æµ‹è¯•åŠ¨ä½œé€‰æ‹©ï¼ˆå•ä¸ªè§‚æµ‹ï¼‰
    selected_actions = policy.select_action(observations)
    print(f"  - å•è§‚æµ‹åŠ¨ä½œé€‰æ‹©: {selected_actions.shape}")
    
    # æµ‹è¯•åºåˆ—è§‚æµ‹ï¼ˆå¦‚æœActoræ”¯æŒï¼‰
    if hasattr(policy.actor, 'obs_history_length'):
        obs_sequence = [observations for _ in range(3)]
        # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½éœ€è¦ä¿®æ”¹select_actionä»¥æ”¯æŒåºåˆ—è¾“å…¥
        # selected_actions_seq = policy.select_action(obs_sequence)
        # print(f"  - åºåˆ—è§‚æµ‹åŠ¨ä½œé€‰æ‹©: {selected_actions_seq.shape}")
    
    # æµ‹è¯•æŸå¤±è®¡ç®—
    batch = {
        "state": observations,
        "action": actions,
        "expert_action": expert_actions,
        "training_step": 100,
    }
    
    loss_dict = policy.forward(batch, model="actor")
    print(f"  - ActoræŸå¤±: {loss_dict['loss_actor'].item():.4f}")
    
    print("âœ… åºåˆ—ACT-SAC Actoræµ‹è¯•é€šè¿‡")


def test_bc_weight_decay():
    """æµ‹è¯•BCæƒé‡è¡°å‡"""
    print("\nâš–ï¸ æµ‹è¯•BCæƒé‡è¡°å‡...")
    
    config = create_test_config(use_act_actor=True)
    policy = SACPolicy(config=config)
    
    observations, actions, expert_actions = create_test_data()
    
    # æµ‹è¯•ä¸åŒè®­ç»ƒæ­¥æ•°çš„æƒé‡
    steps = [0, 250, 500, 750, 1000, 1500]
    
    for step in steps:
        weight = policy._compute_dynamic_bc_weight(step)
        print(f"  - æ­¥æ•° {step:4d}: BCæƒé‡ = {weight:.4f}")
    
    print("âœ… BCæƒé‡è¡°å‡æµ‹è¯•é€šè¿‡")


def test_compatibility():
    """æµ‹è¯•å…¼å®¹æ€§"""
    print("\nğŸ”„ æµ‹è¯•å…¼å®¹æ€§...")
    
    # æµ‹è¯•é…ç½®åˆ‡æ¢
    configs = [
        ("ä¼ ç»ŸSAC", create_test_config(use_act_actor=False)),
        ("ACT-SAC", create_test_config(use_act_actor=True, use_sequence=False)),
        ("åºåˆ—ACT-SAC", create_test_config(use_act_actor=True, use_sequence=True)),
    ]
    
    for name, config in configs:
        try:
            policy = SACPolicy(config=config)
            observations, _, _ = create_test_data()
            actions = policy.select_action(observations)
            print(f"  - {name}: âœ… (åŠ¨ä½œå½¢çŠ¶: {actions.shape})")
        except Exception as e:
            print(f"  - {name}: âŒ é”™è¯¯: {e}")
    
    print("âœ… å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ACT-SACæµ‹è¯•...")
    
    try:
        # åŸºç¡€åŠŸèƒ½æµ‹è¯•
        test_traditional_sac()
        test_act_sac()
        test_sequence_act_sac()
        
        # ç‰¹æ®ŠåŠŸèƒ½æµ‹è¯•
        test_bc_weight_decay()
        test_compatibility()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ACT-SACå®ç°æ­£ç¡®ã€‚")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
